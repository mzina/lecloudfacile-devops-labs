# En premier lieu nous qllons importer le module dag depuis le package airflow
from airflow import DAG
from airflow.operators.bash import BashOperator
import logging
#
from datetime import datetime, timedelta
# Nous allons ensuite creer un instance DAG
default_args = {
    'owner': 'pmf',
    'retries': 5,
    'retry_delay': timedelta(minutes=2)
}
with DAG(
    dag_id='mon-dag_v2',
    description='mon premier dag sur airflow',
    # On definit Quand notre dag sera execute et pour combien de fois
    start_date=datetime(2024, 9, 19, 23, 50),
    schedule_interval='@daily',
    # Ensuite on definira les paramatres en commun qui seront utilise pour initialiser l'operateurs en default_args
    default_args=default_args
 ) as dag:
 # Pour creer un task, on aura besoin d'importer bashOperateur from airflow.operator.bash
    task1 = BashOperator(
        task_id='mon_premier_tache',
        bash_command="echo Hello airflowers!!!, this is my first task"
    )
    logger = logging.getLogger(__name__)
    logger.info("This is a log message")
    task2 = BashOperator(
        task_id='second_tache',
        bash_command="echo Hello i am task2!!!"
    )
    task1.set_downstream(task2)